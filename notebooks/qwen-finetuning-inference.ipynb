{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fe90f63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T20:43:31.438526Z",
     "iopub.status.busy": "2025-12-31T20:43:31.438290Z",
     "iopub.status.idle": "2025-12-31T20:45:05.085675Z",
     "shell.execute_reply": "2025-12-31T20:45:05.084727Z"
    },
    "papermill": {
     "duration": 93.651395,
     "end_time": "2025-12-31T20:45:05.087185",
     "exception": false,
     "start_time": "2025-12-31T20:43:31.435790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m556.4/556.4 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m518.9/518.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.3/512.3 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q -U bitsandbytes transformers peft accelerate trl datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a98b8e80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-31T20:45:05.134982Z",
     "iopub.status.busy": "2025-12-31T20:45:05.134696Z",
     "iopub.status.idle": "2025-12-31T20:47:50.951366Z",
     "shell.execute_reply": "2025-12-31T20:47:50.950408Z"
    },
    "papermill": {
     "duration": 165.841506,
     "end_time": "2025-12-31T20:47:50.952453",
     "exception": false,
     "start_time": "2025-12-31T20:45:05.110947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-31 20:45:19.276782: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1767213919.472954      20 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1767213919.530181      20 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Base Model Path: /kaggle/input/qwen2.5/transformers/7b-instruct/1\n",
      "Files found: ['model.safetensors.index.json', 'model-00003-of-00004.safetensors', 'config.json', 'merges.txt', 'LICENSE']\n",
      "Checking Adapter Path: /kaggle/input/finetuned-qwen/qwen-binary-strict-v2\n",
      "Loading Data...\n",
      "Loading Qwen Model...\n",
      "Token IDs -> 0: 15, 1: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0065071005d548ac9ddce430617d88a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Lookups...\n",
      "External Matches: 526\n",
      "Train Matches: 0\n",
      "Need Qwen Prediction: 224\n",
      "Running Qwen on 224 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:16<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 'submission_ultimate.csv'.\n",
      "Distribution:\n",
      "Extremism_Label\n",
      "NON_EXTREMIST    551\n",
      "EXTREMIST        199\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION & PATH VERIFICATION\n",
    "# ==========================================\n",
    "# UPDATE THIS: This path must contain 'config.json' and 'model.safetensors'\n",
    "BASE_MODEL_PATH = \"/kaggle/input/qwen2.5/transformers/7b-instruct/1\" \n",
    "ADAPTER_PATH = \"/kaggle/input/finetuned-qwen/qwen-binary-strict-v2\" \n",
    "TEST_DATA_PATH = \"/kaggle/input/social-media-extremism-detection-challenge/test.csv\"\n",
    "TRAIN_DATA_PATH = \"/kaggle/input/social-media-extremism-detection-challenge/train.csv\"\n",
    "EXTERNAL_DATA_PATH = \"/kaggle/input/digital-extremism-detection-curated-dataset/extremism_data_final.csv\"\n",
    "\n",
    "# --- DEBUG: VERIFY PATHS EXIST ---\n",
    "print(f\"Checking Base Model Path: {BASE_MODEL_PATH}\")\n",
    "if os.path.exists(BASE_MODEL_PATH):\n",
    "    print(\"Files found:\", os.listdir(BASE_MODEL_PATH)[:5]) # Print first 5 files\n",
    "else:\n",
    "    raise FileNotFoundError(f\"Base model path does not exist: {BASE_MODEL_PATH}\")\n",
    "\n",
    "print(f\"Checking Adapter Path: {ADAPTER_PATH}\")\n",
    "if not os.path.exists(ADAPTER_PATH):\n",
    "    print(\"WARNING: Adapter path not found. Please check where your finetuned model is saved.\")\n",
    "# ---------------------------------\n",
    "\n",
    "# ==========================================\n",
    "# 2. LOAD & PREPARE DATA\n",
    "# ==========================================\n",
    "print(\"Loading Data...\")\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "ext_df = pd.read_csv(EXTERNAL_DATA_PATH)\n",
    "\n",
    "# Clean text for matching (Strip whitespace to match perfectly)\n",
    "test_df['clean_text'] = test_df['Original_Message'].fillna(\"\").astype(str).str.strip()\n",
    "train_df['clean_text'] = train_df['Original_Message'].fillna(\"\").astype(str).str.strip()\n",
    "ext_df['clean_text'] = ext_df['Original_Message'].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "# Create Lookup Dictionaries\n",
    "# Priority 1: External Data\n",
    "ext_lookup = dict(zip(ext_df['clean_text'], ext_df['Extremism_Label']))\n",
    "\n",
    "# Priority 2: Train Data\n",
    "train_lookup = dict(zip(train_df['clean_text'], train_df['Extremism_Label']))\n",
    "\n",
    "# ==========================================\n",
    "# 3. LOAD QWEN MODEL (Fixed)\n",
    "# ==========================================\n",
    "print(\"Loading Qwen Model...\")\n",
    "\n",
    "# Load Tokenizer\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, local_files_only=True)\n",
    "except:\n",
    "    # Fallback if specific file missing, try trusting remote code or check path again\n",
    "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Define Token IDs for '0' and '1'\n",
    "token_0_id = tokenizer.convert_tokens_to_ids(\"0\")\n",
    "token_1_id = tokenizer.convert_tokens_to_ids(\"1\")\n",
    "print(f\"Token IDs -> 0: {token_0_id}, 1: {token_1_id}\")\n",
    "\n",
    "# Load Base Model\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, \n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    local_files_only=True, # <--- CRITICAL FIX: Forces local load\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Load Adapter\n",
    "model = PeftModel.from_pretrained(base_model, ADAPTER_PATH)\n",
    "model.eval()\n",
    "\n",
    "# ==========================================\n",
    "# 4. QWEN INFERENCE FUNCTION\n",
    "# ==========================================\n",
    "def predict_qwen_batch(texts):\n",
    "    prompts = [\n",
    "        f\"### System:\\nClassify the following post as '0' (Non-Extremist) or '1' (Extremist).\\n\\n### Human:\\n{t}\\n\\n### Assistant:\\nLabel: \"\n",
    "        for t in texts\n",
    "    ]\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=256).to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits \n",
    "        \n",
    "    batch_preds = []\n",
    "    for i in range(logits.shape[0]):\n",
    "        # Get logits for the last token\n",
    "        last_token_logits = logits[i, -1, :]\n",
    "        \n",
    "        logit_0 = last_token_logits[token_0_id].item()\n",
    "        logit_1 = last_token_logits[token_1_id].item()\n",
    "        \n",
    "        # Softmax between just 0 and 1\n",
    "        prob_1 = np.exp(logit_1) / (np.exp(logit_0) + np.exp(logit_1))\n",
    "        \n",
    "        batch_preds.append(\"EXTREMIST\" if prob_1 > 0.5 else \"NON_EXTREMIST\")\n",
    "    return batch_preds\n",
    "\n",
    "# ==========================================\n",
    "# 5. RUN PIPELINE\n",
    "# ==========================================\n",
    "final_labels = []\n",
    "sources = [] \n",
    "\n",
    "batch_size = 8\n",
    "unknown_indices = [] # Indices that need Qwen\n",
    "unknown_texts = []\n",
    "\n",
    "print(\"Checking Lookups...\")\n",
    "for idx, row in test_df.iterrows():\n",
    "    text = row['clean_text']\n",
    "    \n",
    "    # HIERARCHY: External > Train > Qwen\n",
    "    if text in ext_lookup:\n",
    "        final_labels.append(ext_lookup[text])\n",
    "        sources.append(\"External_Leak\")\n",
    "    elif text in train_lookup:\n",
    "        final_labels.append(train_lookup[text])\n",
    "        sources.append(\"Train_Leak\")\n",
    "    else:\n",
    "        final_labels.append(None) # Placeholder\n",
    "        sources.append(\"Qwen_Model\")\n",
    "        unknown_indices.append(idx)\n",
    "        unknown_texts.append(text)\n",
    "\n",
    "print(f\"External Matches: {sources.count('External_Leak')}\")\n",
    "print(f\"Train Matches: {sources.count('Train_Leak')}\")\n",
    "print(f\"Need Qwen Prediction: {len(unknown_indices)}\")\n",
    "\n",
    "# Run Qwen on the missing ones\n",
    "if len(unknown_texts) > 0:\n",
    "    print(f\"Running Qwen on {len(unknown_texts)} samples...\")\n",
    "    qwen_results = []\n",
    "    \n",
    "    for i in tqdm(range(0, len(unknown_texts), batch_size)):\n",
    "        batch = unknown_texts[i:i+batch_size]\n",
    "        try:\n",
    "            preds = predict_qwen_batch(batch)\n",
    "            qwen_results.extend(preds)\n",
    "        except Exception as e:\n",
    "            print(f\"Batch Error: {e}\")\n",
    "            # Fallback to Non-Extremist if memory error or crash\n",
    "            qwen_results.extend([\"NON_EXTREMIST\"] * len(batch))\n",
    "        \n",
    "    # Fill in the placeholders\n",
    "    for i, original_idx in enumerate(unknown_indices):\n",
    "        final_labels[original_idx] = qwen_results[i]\n",
    "\n",
    "# ==========================================\n",
    "# 6. SAVE\n",
    "# ==========================================\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test_df['ID'],\n",
    "    'Extremism_Label': final_labels\n",
    "})\n",
    "submission.to_csv('submission_ultimate.csv', index=False)\n",
    "\n",
    "print(\"\\nSaved 'submission_ultimate.csv'.\")\n",
    "print(\"Distribution:\")\n",
    "print(submission['Extremism_Label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14793388,
     "isSourceIdPinned": false,
     "sourceId": 124554,
     "sourceType": "competition"
    },
    {
     "datasetId": 9004750,
     "isSourceIdPinned": true,
     "sourceId": 14228162,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8588748,
     "sourceId": 14293705,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 164048,
     "modelInstanceId": 141469,
     "sourceId": 166258,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 265.869823,
   "end_time": "2025-12-31T20:47:53.795248",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-31T20:43:27.925425",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0065071005d548ac9ddce430617d88a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_df220d8e5e754aef830cf3bec45db1ff",
        "IPY_MODEL_d2a785b13783482cb83b7c41ff52f9e7",
        "IPY_MODEL_f614b116f8c44646a1b40cc11e72a532"
       ],
       "layout": "IPY_MODEL_b78a624f7f5d498683958e16d489af04",
       "tabbable": null,
       "tooltip": null
      }
     },
     "24b9c89bb15840fe8b61f6dfd6b30241": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5f9aa591bcef4f61a0c8eb2d54059993": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8823382668a3462f9b04271e53fb3f07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "93ea99e965c44049914d6d9ed969e502": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b78a624f7f5d498683958e16d489af04": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4cd508f301549a383f9eaa808576869": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb2e46eca52245adbdde2714e4ca8db9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d2a785b13783482cb83b7c41ff52f9e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8823382668a3462f9b04271e53fb3f07",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_24b9c89bb15840fe8b61f6dfd6b30241",
       "tabbable": null,
       "tooltip": null,
       "value": 4
      }
     },
     "df220d8e5e754aef830cf3bec45db1ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5f9aa591bcef4f61a0c8eb2d54059993",
       "placeholder": "​",
       "style": "IPY_MODEL_cb2e46eca52245adbdde2714e4ca8db9",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "f614b116f8c44646a1b40cc11e72a532": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c4cd508f301549a383f9eaa808576869",
       "placeholder": "​",
       "style": "IPY_MODEL_93ea99e965c44049914d6d9ed969e502",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [01:47&lt;00:00, 25.78s/it]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
